# Illumio Coding Assignment

## Overview
This project is a Java-based solution to parse AWS VPC flow logs and map each log entry to a tag based on a lookup table. The program generates two output files:

- `tag_counts.csv`: Count of matches for each tag.
- `port_protocol_counts.csv`: Count of matches for each port/protocol combination.

The solution is designed to handle large flow log files (up to 10 MB) and lookup tables with up to 10,000 mappings. It adheres to the requirements provided by Illumio, including support for the default log format (version 2) and case-insensitive matching.

## Table of Contents
- [Assumptions](#assumptions)
- [Algorithm](#algorithm)
- [Input and Output](#input-and-output)
- [Test Cases](#test-cases)
- [How to Compile and Run](#how-to-compile-and-run)
- [Performance Analysis](#performance-analysis)
- [Generating Test Data](#generating-test-data)
- [Conclusion](#conclusion)

## Assumptions
### Flow Log Format:
- The program only supports the default log format (version 2) as specified by AWS VPC Flow Logs.
- The 7th field is assumed to be the destination port (`dstport`).
- The 8th field is assumed to be the protocol.
- Reference: [AWS VPC Flow Logs Documentation](https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html).

### Lookup Table:
- The lookup table is a CSV file with three columns: `dstport`, `protocol`, and `tag`.
- Multiple tags can map to the same `dstport,protocol` combination.

### Output Files:
- The `tag_counts.csv` file is sorted alphabetically by tag.
- The `port_protocol_counts.csv` file is sorted numerically by port.

### Case Insensitivity:
- The program performs case-insensitive matching for `dstport` and `protocol`.

### Untagged Logs:
- Log entries that do not match any entry in the lookup table are counted under the `Untagged` tag.

## Algorithm
1. **Load Lookup Table:**
   - The `LookupTable` class reads the lookup table from a CSV file and stores it in a `Map<String, List<String>>`. The key is a combination of `dstport,protocol`, and the value is a list of tags.

2. **Parse Flow Logs:**
   - The `FlowLogParser` class reads the flow log file line by line.
   - For each log entry, it extracts the `dstport` and `protocol` fields.
   - It queries the lookup table to get the corresponding tags and updates the counts in `tagCounts` and `portProtocolCounts`.

3. **Generate Outputs:**
   - The `tag_counts.csv` file is generated by sorting the `tagCounts` map alphabetically.
   - The `port_protocol_counts.csv` file is generated by sorting the `portProtocolCounts` map numerically by port.

### Efficiency:
- The program uses `HashMap` for O(1) lookups in the lookup table.
- Sorting the outputs is done in O(n log n) time, where `n` is the number of unique tags or port/protocol combinations.

## Input and Output
### Input Files
#### `flow_logs.txt`
Contains flow log entries in the default AWS VPC Flow Logs format (version 2).

**Example:**
```txt
2 123456789012 eni-0a1b2c3d 10.0.1.201 198.51.100.2 49153 443 6 25 20000 1620140761 1620140821 ACCEPT OK
```

#### `lookup_table.csv`
Contains mappings of `dstport,protocol` to tags.

**Example:**
```csv
dstport,protocol,tag
443,tcp,sv_P2
23,tcp,sv_P1
```

### Output Files
#### `tag_counts.csv`
Contains the count of matches for each tag, sorted alphabetically.

**Example:**
```csv
Tag,Count
Untagged,0
sv_P1,1
sv_P2,1
```

#### `port_protocol_counts.csv`
Contains the count of matches for each port/protocol combination, sorted numerically by port.

**Example:**
```csv
Port,Protocol,Count
23,tcp,1
443,tcp,1
```

## Test Cases
The project includes **20 test cases** to ensure the program works correctly under various conditions. Each test case has:
- A `flow_logs.txt` file.
- A `lookup_table.csv` file.
- An `expected_output/` directory containing the expected `tag_counts.csv` and `port_protocol_counts.csv`.

### **Detailed Test Cases**
1. **Basic Test:** Verifies correct tag mapping and counting.
2. **Multiple Tags for Same Port/Protocol:** Ensures all tags are counted.
3. **Untagged Logs:** Ensures untagged logs are correctly handled.
4. **Case Insensitivity:** Ensures case-insensitive matching.
5. **Large File:** Tests performance with a 10 MB flow log file.
6. **Mixed Protocols:** Verifies handling of TCP, UDP, and ICMP.
7. **Invalid Log Entries:** Ensures invalid logs are skipped.
8. **Large Lookup Table:** Tests efficiency with 10,000 mappings.
9. **ICMP Protocol:** Checks handling of ICMP traffic.
10. **Multiple Tags for Same Log Entry:** Validates handling of multiple tags assigned to a single log entry.
11. **Mixed Case in Lookup Table:** Ensures proper matching when lookup table contains mixed case protocol values.
12. **Large Port Numbers:** Tests handling of ports up to `65535`.
13. **Zero Port:** Ensures logs with `dstport=0` are processed.
14. **UDP Protocol:** Verifies handling of UDP logs.
15. **Unknown Protocol:** Ensures unknown protocols are counted.
16. **Multiple Logs with Same Port/Protocol:** Ensures correct aggregation.
17. **Mixed Tags for Same Port/Protocol:** Validates multiple tag handling.
18. **Large Number of Tags:** Tests lookup table scalability.
19. **Empty Flow Logs:** Ensures empty files generate empty output.
20. **Empty Lookup Table:** Ensures all logs default to `Untagged`.
19. **Duplicate Tags:** Checks for correct duplicate tag counting.
20. **Special Characters in Tags:** Ensures special character handling.

## How to Compile and Run
### Compile the Code
Navigate to the project directory:
```bash
cd illumio-assessment
```
Compile the Java code:
```bash
javac src/com/illumio/*.java -d out/
```

### Run the Program
Run the program with input and output directories:
```bash
java -cp out com.illumio.Main input output
```

### Run Test Cases
Make the test script executable:
```bash
chmod +x run_tests.sh
```
Run the test script:
```bash
./run_tests.sh
```

## Performance Analysis
### Time Complexity:
- Loading the lookup table: **O(n)**, where `n` is the number of mappings.
- Parsing flow logs: **O(m)**, where `m` is the number of log entries.
- Sorting outputs: **O(k log k)**, where `k` is the number of unique tags or port/protocol combinations.

### Space Complexity:
- **O(n + m)** for storing the lookup table and flow log data.

## Generating Test Data
To generate large flow logs and lookup tables for testing, Python scripts are provided:

### `generate_flow_logs.py`
Generates a 10 MB flow log file with random entries.

### `generate_lookup_table.py`
Generates a lookup table with 10,000 mappings.

Run the scripts as follows:
```bash
python generate_flow_logs.py
python generate_lookup_table.py
```

## Conclusion
This project demonstrates a robust and efficient solution for parsing AWS VPC flow logs and mapping them to tags. It adheres to the requirements, handles edge cases, and is optimized for performance. The inclusion of 20 test cases ensures the program works correctly under various conditions. The code is well-structured, easy to understand, and can be run on any local machine without additional dependencies.
